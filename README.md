# Final-Project-Transforming-and-Analyzing-Data-with-SQL

## Project/Goals
The goal of this project is to clean, transform, and analyze data from e-commerce sessions, focusing on understanding customer behavior, identifying key metrics, and ensuring data integrity. The main objectives include:

### 1. Cleaning the data by removing duplicates, handling missing values, and ensuring consistent units of measurement.
### 2. Analyzing patterns in visitor behavior, including repeat visitors, revenue generation by city/country, product popularity, and conversion rates.
### 3. Establishing primary and foreign keys to improve data structure and query performance.
### 4. Creating queries that answer specific business questions, such as identifying top-selling products by location and calculating conversion rates.

## Process
### Step 1: Data Cleaning

Removing Duplicates: Identified and removed duplicate rows in the analytics table using ROW_NUMBER() and ctid to allow for better primary key and foreign key management. This involved creating a temporary table and indexing key columns to optimize query performance.

Handling Null Values: Replaced NULL values in the revenue column with 0 to maintain consistency in revenue calculations.

Correcting Units: Updated the unit_price column to use consistent units by dividing by 1,000,000, assuming prices were stored in an incorrect unit.

Setting Default Values: Filled missing values in the v2_product_category column with '(not set)' to prevent gaps in analysis based on product categories.

### Step 2: Data Analysis

Identifying Patterns in Visitor Behavior: Used SQL queries to calculate repeat visitor counts, top-selling products by city/country, and average session duration per location.

Calculating Conversion Rate: Determined the percentage of visitors who made a purchase by comparing total unique visitors to those with a units_sold value greater than zero.

Revenue and Product Analysis: Analyzed total revenue generated by different cities/countries and identified which product categories were the most popular across regions.

### Step 3: Query Optimization

Indexing: Created indexes on key columns (full_visitor_id, visit_id, visit_start_time, unit_price, and revenue) to improve query performance, especially for removing duplicates and grouping data.

Validation: Tested the final queries on a sample of the dataset to validate results and ensure accuracy.

## Results
The results of this project provide some insights, but they should be interpreted with caution due to several data quality limitations:

### Data Completeness: 

The dataset has numerous missing values, especially in key columns like revenue and v2_product_category. These missing values affect the accuracy of metrics such as total revenue and product popularity.

### Uncertain Data Source and Collection Method: 

Without knowing how the data was gathered or having documentation on its structure, itâ€™s difficult to fully trust the results. A thorough understanding of the data's origin and collection process would enable a more effective QA process, helping to clarify data consistency and reliability.

### Limitations of Assumptions: 

Assumptions were made to handle missing values and ambiguous data (e.g., setting default values, assuming units of measurement), which may impact the results' validity.

Despite these challenges, I ran queries to derive meaningful insights to the best of my knowledge. Key findings include general trends in revenue by location, product popularity, and conversion rates. However, the results should be considered preliminary, with further QA and data source clarification needed to ensure reliable insights.

## Challenges 
This project presented several challenges:

### 1. Handling Duplicates: 

Without primary keys, removing duplicates was complex and required using the ctid column. The process was slow initially, but adding indexes improved the performance.

### 2. Data Completeness: 

Many fields, such as revenue and v2_product_category, had missing values, requiring assumptions and setting defaults to make the data usable.

### 3. Unclear Units: 

Columns like unit_price and time_on_site lacked clear units, requiring assumptions about data interpretation. Naming columns with units or adding metadata would have been beneficial.

### 4. Query Performance: 

Some queries, especially those involving large aggregations or duplicate removal, were slow. Indexing helped, but more optimizations could be explored.


## Future Goals
### 1. Improving Data Documentation: 

Adding metadata to specify units, explain columns, and describe data sources would improve future usability.

### 2. Data Cleaning: 

Implement a repeatable process for data cleaning, especially for removing duplicates and handling missing values, to reduce manual effort.

### 3. Advanced Analysis: 

Explore deeper analyses, such as clustering customers by behavior or predicting future revenue based on current trends.
